<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Diffusion Model for Dense Matching">
  <meta name="keywords" content="Diffusion, Matching">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Diffusion Model for Dense Matching</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Diffusion Model for Dense Matching</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=ko&user=xakYe8MAAAAJ">Jisu Nam</a>,</span>
            <span class="author-block">
              <a href="https://gseonglee.github.io/">Gyuseong Lee</a>,</span>
            <span class="author-block">
              <a href="https://github.com/sunwoo76">Sunwoo Kim</a>,
            </span>
            <span class="author-block">
              <a href="https://ines-hyeonsu-kim.github.io">Hyeonsu Kim</a>,
            </span>
            <span class="author-block">
              Hyoungwon Cho</a>,
            </span>
            <span class="author-block">
              Seyeon Kim</a>,
            </span>
            <span class="author-block">
              <a href="https://cvlab.korea.ac.kr/members/faculty">Seungryong Kim</a>
            </span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Korea University</span>
          </div>

          <h1 class="title is-4 publication-title">ICLR 2024, Oral</h1>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/abs/2305.19094"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            
              <span class="link-block">
                <a href="https://github.com/KU-CVLAB/DiffMatch"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

 <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <div style="display: flex; justify-content: center;">
            <div style="flex: 1; display: flex; flex-direction: column; align-items: center; margin-right: 3px;">
                <img src="static/images/src_1.png" alt="Source Image" style="width:100%;"/>
                <img src="static/images/src_2.png" alt="Source Image" style="width:100%;"/>
            </div>
            <div style="flex: 1; display: flex; flex-direction: column; align-items: center; margin-right: 3px;">
                <img src="static/images/trg_1.png" alt="Target Image" style="width:100%;"/>
                <img src="static/images/trg_2.png" alt="Target Image" style="width:100%;"/>
            </div>
            <div style="flex: 1; display: flex; flex-direction: column; align-items: center; margin-right: 3px;">
                <img src="static/images/vis_1.gif" alt="Diff Match Image" style="width:100%;"/>
                <img src="static/images/vis_2.gif" alt="Diff Match Image" style="width:100%;"/>
            </div>
            <div style="flex: 1; display: flex; flex-direction: column; align-items: center;">
                <img src="static/images/warped_1.png" alt="GT Image" style="width:100%;"/>
                <img src="static/images/warped_2.png" alt="GT Image" style="width:100%;"/>
            </div>
        </div>
        <div style="display: flex; justify-content: center;">
            <div style="flex: 1; display: flex; justify-content: center; margin-right: 3px;">
                <span style="text-align: center;">Source</span>
            </div>
            <div style="flex: 1; display: flex; justify-content: center; margin-right: 3px;">
                <span style="text-align: center;">Target</span>
            </div>
            <div style="flex: 1; display: flex; justify-content: center; margin-right: 3px;">
                <span style="text-align: center;">DiffMatch</span>
            </div>
            <div style="flex: 1; display: flex; justify-content: center;">
                <span style="text-align: center;">GT</span>
            </div>
        </div>
        <div class="content has-text-justified">
            <p style="font-size: 15px;">
              <strong>Visualization of the reverse diffusion process for dense correspondence:</strong> (from left to right) source and target images, warped source images by estimated correspondences as evolving time steps, and ground-truth. The source image is progressively warped into the target image through an iterative denoising process.
            </p>
        </div>
    </div>

    <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <img width="100%" src="static/images/teaser.png"> <br>
          <div style="display: flex; justify-content: center; text-align: center; margin-bottom: 5px;"> 
          <div class="content has-text-justified">
            <p style="font-size: 15px;">
              <strong>Visualizing the effectiveness of the proposed DiffMatch:</strong> (a) source images, (b) target images, and warped source images using estimated correspondences by (c-d) state-of-the-art approaches, (e) our DiffMatch, and (f) ground-truth. Compared to previous methods that discriminatively estimate correspondences, our diffusion-based generative framework effectively learns the matching field manifold, resulting in better estimating correspondences particularly at textureless regions, repetitive patterns, and large displacements.
            </p>
          </div>
        </div>
      </div>
    </div>  
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p style="font-size: 15px;">
            The objective for establishing dense correspondence between paired images consists of two terms: a data term and a prior term. While conventional techniques focused on defining hand-designed prior terms, which are difficult to formulate, recent approaches have focused on learning the data term with deep neural networks without explicitly modeling the prior, assuming that the model itself has the capacity to learn an optimal prior from a large-scale dataset. The performance improvement was obvious, however, they often fail to address inherent ambiguities of matching, such as textureless regions, repetitive patterns, large displacements, or noises. To address this, we propose <i>DiffMatch</i>, a novel conditional diffusion-based framework designed to explicitly model both the data and prior terms for dense matching. This is accomplished by leveraging a conditional denoising diffusion model that explicitly takes matching cost and injects the prior within generative process. However, limited resolution of the diffusion model is a major hindrance. We address this with a cascaded pipeline, starting with a low-resolution model, followed by a super-resolution model that successively upsamples and incorporates finer details to the matching field. Our experimental results demonstrate significant performance improvements of our method over existing approaches, and the ablation studies validate our design choices along with the effectiveness of each component.
          </p>
        </div>
      </div>
    </div>
    <br>
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Framework</h2>
          <img width="100%" src="static/images/diffmatch_overall.png"> <br>
          <div style="display: flex; justify-content: center; text-align: center; margin-bottom: 5px;">
            
          <div class="content has-text-justified">
            <p style="font-size: 15px;">
              <strong>Overall network architecture of DiffMatch.</strong> Given source and target images, our conditional diffusion-based network estimates the dense correspondence between the two images. We leverage two conditions: the initial correspondence and the local matching cost, which finds long-range matching and embeds local pixel-wise interactions, respectively.
            </p>
          </div>
        </div>
      </div>
    </div> 
    <br>

    
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Matching Results</h2>
          <img style="max-width: 100%;" src="static/images/hpatches.png">
          <div class="content has-text-justified">
            <p style="font-size: 15px;">
              <strong>Qualitative results on HPatches:</strong> the source images are warped to the target images using predicted correspondences.
            </p>
          </div>
       
          <img style="max-width: 100%;" src="static/images/eth3d.png">
          <div class="content has-text-justified">
            <p style="font-size: 15px;">
              <strong>Qualitative results on ETH3D:</strong> the source images are warped to the target images using predicted correspondences.
            </p>
          </div>

          <img style="max-width: 100%;" src="static/images/hp_perturb_final-1.png">
          <div class="content has-text-justified">
            <p style="font-size: 15px;">
              <strong>Qualitative results on HPatches using corruptions in ImageNet-C:</strong> the source images are warped to the target images using predicted correspondences.
            </p>
          </div>

          <img style="max-width: 100%;" src="static/images/eth3d_perturb-1.png">
          <div class="content has-text-justified">
            <p style="font-size: 15px;">
              <strong>Qualitative results on ETH3D using corruptions in ImageNet-C:</strong> the source images are warped to the target images using predicted correspondences.
                 
            </p>
          </div>
        </div>
      </div>
    </div>
    <br>
    <br>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{nam2023diffmatch,
      title={DiffMatch: Diffusion Model for Dense Matching}, 
      author={Jisu Nam and Gyuseong Lee and Sunwoo Kim and Hyeonsu Kim and Hyoungwon Cho and Seyeon Kim and Seungryong Kim},
      year={2023},
      eprint={2305.19094},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/list/cs/new">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/KU-CVLAB/DiffMatch" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://ku-cvlab.github.io/DiffMatch/">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
